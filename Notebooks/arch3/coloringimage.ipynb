{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnO6IGXhjfak",
        "colab_type": "code",
        "outputId": "12615e58-9f8a-45b2-fe81-128c41f6c5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import cv2\n",
        "from keras import backend as k\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, BatchNormalization, UpSampling2D, Dropout, Flatten, Dense, Input, LeakyReLU, Conv2DTranspose,AveragePooling2D, Concatenate\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import set_random_seed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from PIL import Image\n",
        "from skimage import color, io\n",
        "from zipfile import ZipFile \n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(1)\n",
        "set_random_seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0VdGo4jg5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "  'Generates data for Keras'\n",
        "  \n",
        "  def __init__(self, list_IDs, zip_file, batch_size=32, dim=(256, 256), n_channels=2, shuffle=True):\n",
        "    'Initialization'\n",
        "    self.dim = dim\n",
        "    self.batch_size = batch_size\n",
        "    self.list_IDs = list_IDs\n",
        "    self.zip_file = zip_file\n",
        "    self.n_channels = n_channels\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()            # shuffle data on the beginning\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the number of batches per epoch'\n",
        "    return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    'Generate one batch of data'\n",
        "    # Generate indexes of the batch\n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    # Find list of IDs\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "    # Generate data\n",
        "    X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    'Updates indexes after each epoch'\n",
        "    self.indexes = np.arange(len(self.list_IDs))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "    'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "    # Initialization\n",
        "    y = np.empty((self.batch_size, *self.dim, self.n_channels), dtype=np.float32)\n",
        "    X = np.empty((self.batch_size, *self.dim, 1), dtype=np.float32)\n",
        "\n",
        "    # Generate data\n",
        "    for i, ID in enumerate(list_IDs_temp):\n",
        "      img_rgb = np.array(Image.open(BytesIO(self.zip_file.read(ID))).convert('RGB')) / 255\n",
        "      img_lab = color.rgb2lab(img_rgb)\n",
        "      l_channel = img_lab[:,:,0]\n",
        "      l_channel = l_channel / 50 - 1\n",
        "      l_channel = l_channel[...,np.newaxis]\n",
        "\n",
        "      ab_channels = img_lab[:,:,1:]\n",
        "      ab_channels = (ab_channels + 128) / 255 * 2 - 1\n",
        "      \n",
        "      y[i,] = ab_channels\n",
        "      X[i,] = l_channel\n",
        "            \n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y9cZoTwkB5Y",
        "colab_type": "code",
        "outputId": "60a3001a-5b22-462d-ca70-77b3134dfa9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2204
        }
      },
      "source": [
        "Input_train=Input((256,256,1))\n",
        "\n",
        "#encoder part\n",
        "c1=Conv2D(64,(4,4),padding='same',strides=(1,1),name='conv1')(Input_train)\n",
        "c1=BatchNormalization()(c1)\n",
        "c1=LeakyReLU(alpha=0.2)(c1)\n",
        "c2=Conv2D(64,(4,4),padding='same',strides=(2,2),name='conv2')(c1)\n",
        "c2=BatchNormalization()(c2)\n",
        "c2=LeakyReLU(alpha=0.2)(c2)\n",
        "c3=Conv2D(128,(4,4),padding='same',strides=(2,2),name='conv3')(c2)\n",
        "c3=BatchNormalization()(c3)\n",
        "c3=LeakyReLU(alpha=0.2)(c3)\n",
        "c4=Conv2D(256,(4,4),padding='same',strides=(2,2),name='conv4')(c3)\n",
        "c4=BatchNormalization()(c4)\n",
        "c4=LeakyReLU(alpha=0.2)(c4)\n",
        "c5=Conv2D(512,(4,4),padding='same',strides=(2,2),name='conv5')(c4)\n",
        "c5=BatchNormalization()(c5)\n",
        "c5=LeakyReLU(alpha=0.2)(c5)\n",
        "c6=Conv2D(512,(4,4),padding='same',strides=(2,2),name='conv6')(c5)\n",
        "c6=BatchNormalization()(c6)\n",
        "c6=LeakyReLU(alpha=0.2)(c6)\n",
        "c7=Conv2D(512,(4,4),padding='same',strides=(2,2),name='conv7')(c6)\n",
        "c7=BatchNormalization()(c7)\n",
        "c7=LeakyReLU(alpha=0.2)(c7)\n",
        "c8=Conv2D(512,(4,4),padding='same',strides=(2,2),name='conv8')(c7)\n",
        "c8=BatchNormalization()(c8)\n",
        "c8=LeakyReLU(alpha=0.2)(c8)\n",
        "\n",
        "#decoder part\n",
        "d1=Conv2DTranspose(512,(4,4),padding='same',strides=(2,2),name='deconv1')(c8)\n",
        "d1 = concatenate([d1, c7])\n",
        "d1=BatchNormalization()(d1)\n",
        "d1=Activation(\"relu\")(d1)\n",
        "d2=Conv2DTranspose(512,(4,4),padding='same',strides=(2,2),name='deconv2')(d1)\n",
        "d2 = concatenate([d2, c6])\n",
        "d2=BatchNormalization()(d2)\n",
        "d2=Activation(\"relu\")(d2)\n",
        "d3=Conv2DTranspose(512,(4,4),padding='same',strides=(2,2),name='deconv3')(d2)\n",
        "d3 = concatenate([d3, c5])\n",
        "d3=BatchNormalization()(d3)\n",
        "d3=Activation(\"relu\")(d3)\n",
        "d4=Conv2DTranspose(256,(4,4),padding='same',strides=(2,2),name='deconv4')(d3)\n",
        "d4 = concatenate([d4, c4])\n",
        "d4=BatchNormalization()(d4)\n",
        "d4=Activation(\"relu\")(d4)\n",
        "d5=Conv2DTranspose(128,(4,4),padding='same',strides=(2,2),name='deconv5')(d4)\n",
        "d5 = concatenate([d5, c3])\n",
        "d5=BatchNormalization()(d5)\n",
        "d5=Activation(\"relu\")(d5)\n",
        "d6=Conv2DTranspose(64,(4,4),padding='same',strides=(2,2),name='deconv6')(d5)\n",
        "d6 = concatenate([d6, c2])\n",
        "d6=BatchNormalization()(d6)\n",
        "d6=Activation(\"relu\")(d6)\n",
        "d7=Conv2DTranspose(64,(4,4),padding='same',strides=(2,2),name='deconv7')(d6)\n",
        "d7 = concatenate([d7, c1])\n",
        "d7=BatchNormalization()(d7)\n",
        "d7=Activation(\"relu\")(d7)\n",
        "#last layer\n",
        "last_layer=Conv2D(2,(4,4),padding='same',strides=(1,1),activation='tanh',name='last_layer')(d7)\n",
        "model = Model(inputs=[Input_train], outputs=[last_layer])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 256, 256, 64) 1088        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 128, 128, 64) 65600       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 64, 64, 128)  131200      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, 32, 32, 256)  524544      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, 16, 16, 512)  2097664     leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 512)  2048        conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (Conv2D)                  (None, 8, 8, 512)    4194816     leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 8, 512)    2048        conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv7 (Conv2D)                  (None, 4, 4, 512)    4194816     leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 4, 4, 512)    2048        conv7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 4, 4, 512)    0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv8 (Conv2D)                  (None, 2, 2, 512)    4194816     leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 2, 2, 512)    2048        conv8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 2, 2, 512)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "deconv1 (Conv2DTranspose)       (None, 4, 4, 512)    4194816     leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 4, 1024)   0           deconv1[0][0]                    \n",
            "                                                                 leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 4, 4, 1024)   4096        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 4, 4, 1024)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "deconv2 (Conv2DTranspose)       (None, 8, 8, 512)    8389120     activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 1024)   0           deconv2[0][0]                    \n",
            "                                                                 leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 8, 8, 1024)   4096        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 8, 1024)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "deconv3 (Conv2DTranspose)       (None, 16, 16, 512)  8389120     activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 1024) 0           deconv3[0][0]                    \n",
            "                                                                 leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 1024) 4096        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 1024) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "deconv4 (Conv2DTranspose)       (None, 32, 32, 256)  4194560     activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 512)  0           deconv4[0][0]                    \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 512)  2048        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 512)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "deconv5 (Conv2DTranspose)       (None, 64, 64, 128)  1048704     activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 64, 64, 256)  0           deconv5[0][0]                    \n",
            "                                                                 leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 64, 256)  1024        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 256)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "deconv6 (Conv2DTranspose)       (None, 128, 128, 64) 262208      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 128, 128, 128 0           deconv6[0][0]                    \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 128, 128, 128 512         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 128, 128, 128 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "deconv7 (Conv2DTranspose)       (None, 256, 256, 64) 131136      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 256, 256, 128 0           deconv7[0][0]                    \n",
            "                                                                 leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 256, 256, 128 512         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 256, 256, 128 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "last_layer (Conv2D)             (None, 256, 256, 2)  4098        activation_7[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 42,044,930\n",
            "Trainable params: 42,031,618\n",
            "Non-trainable params: 13,312\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaNNhAWX8sgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/data_b7b_elcima/colored.zip'\n",
        "zip_data =  ZipFile(data_path, 'r')\n",
        "ids = zip_data.namelist()[1:]\n",
        "np.random.shuffle(ids)\n",
        "dev_length = int(0.1 * len(ids))\n",
        "test_length = int(0.05 * len(ids))\n",
        "test_ids = ids[:test_length]\n",
        "dev_ids = ids[test_length:dev_length]\n",
        "train_ids = ids[dev_length:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kQZTpXz9lXd",
        "colab_type": "code",
        "outputId": "125c0c7e-4d6f-4553-a6b5-938d9cc78e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "training_generator = DataGenerator(train_ids, zip_data, batch_size=batch_size)\n",
        "validation_generator = DataGenerator(dev_ids, zip_data, batch_size=batch_size)\n",
        "\n",
        "# compile our model\n",
        "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(filepath = '/content/drive/My Drive/movieColor_{epoch:02d}-{val_loss:.2f}.hdf5')\n",
        "callbacks_list = [checkpoint]\n",
        "# training our model\n",
        "model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs = epochs, callbacks=callbacks_list, verbose=1)\n",
        "model.save(\"/content/drive/My Drive/movieColor.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "1874/1874 [==============================] - 2890s 2s/step - loss: 0.0110 - acc: 0.5302 - val_loss: 0.0081 - val_acc: 0.5358\n",
            "Epoch 2/10\n",
            "1874/1874 [==============================] - 2786s 1s/step - loss: 0.0086 - acc: 0.5395 - val_loss: 0.0073 - val_acc: 0.5616\n",
            "Epoch 3/10\n",
            "1874/1874 [==============================] - 2789s 1s/step - loss: 0.0078 - acc: 0.5509 - val_loss: 0.0072 - val_acc: 0.5442\n",
            "Epoch 4/10\n",
            " 777/1874 [===========>..................] - ETA: 25:56 - loss: 0.0075 - acc: 0.5640"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNjEtNuyp6Ig",
        "colab_type": "code",
        "outputId": "714433c0-5e26-44fc-f454-0448debc4a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "training_generator = DataGenerator(train_ids, zip_data, batch_size=batch_size)\n",
        "validation_generator = DataGenerator(dev_ids, zip_data, batch_size=batch_size)\n",
        "\n",
        "model = load_model('/content/drive/My Drive/movieColor_01-0.01.hdf5')\n",
        "checkpoint = ModelCheckpoint(filepath = '/content/drive/My Drive/movieColor_{epoch:02d}-{val_loss:.2f}.hdf5')\n",
        "callbacks_list = [checkpoint]\n",
        "# training our model\n",
        "model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs = epochs, callbacks=callbacks_list, verbose=1)\n",
        "model.save(\"/content/drive/My Drive/movieColor.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "1874/1874 [==============================] - 2710s 1s/step - loss: 0.0050 - acc: 0.6513 - val_loss: 0.0049 - val_acc: 0.6446\n",
            "Epoch 2/10\n",
            "1874/1874 [==============================] - 2653s 1s/step - loss: 0.0043 - acc: 0.6728 - val_loss: 0.0050 - val_acc: 0.6351\n",
            "Epoch 3/10\n",
            "1874/1874 [==============================] - 2742s 1s/step - loss: 0.0037 - acc: 0.6925 - val_loss: 0.0056 - val_acc: 0.6192\n",
            "Epoch 4/10\n",
            "1874/1874 [==============================] - 2667s 1s/step - loss: 0.0033 - acc: 0.7097 - val_loss: 0.0039 - val_acc: 0.6932\n",
            "Epoch 5/10\n",
            "1874/1874 [==============================] - 2670s 1s/step - loss: 0.0028 - acc: 0.7284 - val_loss: 0.0038 - val_acc: 0.7003\n",
            "Epoch 6/10\n",
            "1874/1874 [==============================] - 2675s 1s/step - loss: 0.0025 - acc: 0.7404 - val_loss: 0.0036 - val_acc: 0.7091\n",
            "Epoch 7/10\n",
            "1874/1874 [==============================] - 2685s 1s/step - loss: 0.0022 - acc: 0.7521 - val_loss: 0.0036 - val_acc: 0.7025\n",
            "Epoch 8/10\n",
            "1874/1874 [==============================] - 2707s 1s/step - loss: 0.0020 - acc: 0.7662 - val_loss: 0.0034 - val_acc: 0.7089\n",
            "Epoch 9/10\n",
            "1874/1874 [==============================] - 2779s 1s/step - loss: 0.0018 - acc: 0.7769 - val_loss: 0.0037 - val_acc: 0.7029\n",
            "Epoch 10/10\n",
            "1874/1874 [==============================] - 2708s 1s/step - loss: 0.0016 - acc: 0.7841 - val_loss: 0.0033 - val_acc: 0.7431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkBGf3BkrEve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}